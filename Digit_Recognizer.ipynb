{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Recognizer",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adarshanand2327/Digit_Recognizer/blob/master/Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ish-FTQ3z5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MosOi_vd4Him",
        "colab_type": "code",
        "outputId": "73d5f54b-ab33-43a3-d065-9b0e68083470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
        "trainset = datasets.MNIST('MNIST_data/', train=True, transform=transform, download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testset = datasets.MNIST('MNIST_data/', train=False, transform=transform, download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 3918718.91it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 58238.08it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 976763.45it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 21712.37it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkCt9lFh6Gd7",
        "colab_type": "code",
        "outputId": "7191358b-8520-42b2-dd77-0b39f4c7ee1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "dataIter = iter(trainloader)\n",
        "images, labels = dataIter.next()\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzocQxR18qWs",
        "colab_type": "code",
        "outputId": "5cb00ef4-f838-4027-acc3-b73a9e8b9d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')\n",
        "print(labels[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADA9JREFUeJzt3WGIHPUdxvHnqdogasRUcx5RqhUp\nBKFJOaTQUFKskh6F6BsxYEmJ9HyhoNIXDRapUgpSGouvhAsJuRQbW0jEQ0o1DWpaUsRErEatJpWI\niZdcJVUjiNbk1xc3ac94O3vZndnZy+/7gWV35z8782O45/4zO7Pzd0QIQD5faroAAM0g/EBShB9I\nivADSRF+ICnCDyRF+IGkCD+QFOEHkjq7lyuzzeWEQM0iwrOZr6ue3/YK22/Y3m97bTfLAtBb7vTa\nfttnSXpT0vWSDkp6QdKqiHit5DP0/EDNetHzXytpf0S8FRGfSnpM0soulgegh7oJ/yJJ70x7f7CY\n9jm2R2zvtr27i3UBqFjtX/hFxKikUYndfqCfdNPzH5J0+bT3lxXTAMwB3YT/BUlX277S9pcl3SJp\nvJqyANSt493+iPjM9p2SnpJ0lqSNEfFqZZUBqFXHp/o6WhnH/EDtenKRD4C5i/ADSRF+ICnCDyRF\n+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k\nRfiBpHo6RDf6z9jYWGn7+++/X9p+1113VVkOeoieH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS6uo8\nv+0Dko5JOi7ps4gYqqIoVGfz5s2l7bfeemtXy3/uuedK27dt29bV8lGfKi7y+W5EvFfBcgD0ELv9\nQFLdhj8kPW17j+2RKgoC0Bvd7vYvi4hDthdK2m77HxGxc/oMxT8F/jEAfaarnj8iDhXPk5Iel3Tt\nDPOMRsQQXwYC/aXj8Ns+z/YFJ19LukHS3qoKA1Cvbnb7ByQ9bvvkcn4XEX+qpCoAtes4/BHxlqRv\nVFgLarBr167S9m7P8xf//DEHcaoPSIrwA0kRfiApwg8kRfiBpAg/kBS37j7DDQ3Ve2HlAw88UNq+\ndevWWtePztHzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSnOc/ww0PD9e6/Hnz5tW6fNSHnh9IivAD\nSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSaht+2xttT9re\nO23aAtvbbe8rni+qt0wAVZtNz79J0opTpq2VtCMirpa0o3gPYA5pG/6I2Cnp6CmTV0oaK16PSbqx\n4roA1KzTY/6BiJgoXh+WNFBRPQB6pOt7+EVE2I5W7bZHJI10ux4A1eq05z9ie1CSiufJVjNGxGhE\nDEVEvSNGAjgtnYZ/XNLq4vVqSU9UUw6AXpnNqb4tkv4m6eu2D9q+TdKDkq63vU/S94r3AOaQtsf8\nEbGqRdN1FdeCOWj+/Pml7YODgy3bJiYmWrahflzhByRF+IGkCD+QFOEHkiL8QFKEH0iKIbrRlUsu\nuaS0ffny5S3btmzZUnE1OB30/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOf5z3Dr168vbb/vvvt6\nVAn6DT0/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFef4znO1al3/48OHS9u3bt9e6fnSOnh9IivAD\nSRF+ICnCDyRF+IGkCD+QFOEHknJElM9gb5T0A0mTEXFNMe1+ST+W9K9itnsj4o9tV2aXrwyVe/fd\nd0vbL7300q6W/8knn5S2Dw8Pt2x75plnulo3ZhYRs7q4YzY9/yZJK2aY/puIWFI82gYfQH9pG/6I\n2CnpaA9qAdBD3Rzz32n7ZdsbbV9UWUUAeqLT8D8i6SpJSyRNSFrXakbbI7Z3297d4boA1KCj8EfE\nkYg4HhEnJK2XdG3JvKMRMRQRQ50WCaB6HYXf9uC0tzdJ2ltNOQB6pe1Pem1vkbRc0sW2D0r6uaTl\ntpdICkkHJN1eY40AatA2/BGxaobJG2qoBTU4erT8RE278/zt7gcwb968rpaP5nCFH5AU4QeSIvxA\nUoQfSIrwA0kRfiApbt19hlu3ruWV15KkDRvKz9q2+8l3OwsXLuzq86gPPT+QFOEHkiL8QFKEH0iK\n8ANJEX4gKcIPJMV5ftTqnnvuadn28MMP97ASnIqeH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS4jz/\nGW7nzp2l7RMTE6Xtg4ODpe3tnH126z+xc889t/SzH3/8cVfrRjl6fiApwg8kRfiBpAg/kBThB5Ii\n/EBShB9Iyu3uy277ckmbJQ1ICkmjEfGw7QWSfi/pCkkHJN0cEf9us6zubgKPyi1evLi0fdeuXaXt\n8+fP73jda9asKW3ftGlTx8vOLCLKx1UvzKbn/0zSTyJisaRvSbrD9mJJayXtiIirJe0o3gOYI9qG\nPyImIuLF4vUxSa9LWiRppaSxYrYxSTfWVSSA6p3WMb/tKyQtlfS8pIGIOHlt6GFNHRYAmCNmfW2/\n7fMlbZV0d0R8aP//sCIiotXxvO0RSSPdFgqgWrPq+W2fo6ngPxoR24rJR2wPFu2DkiZn+mxEjEbE\nUEQMVVEwgGq0Db+nuvgNkl6PiIemNY1LWl28Xi3pierLA1CX2ez2f1vSDyW9YvulYtq9kh6U9Afb\nt0l6W9LN9ZSIOi1durS0vZtTeehvbcMfEX+V1Oq84XXVlgOgV7jCD0iK8ANJEX4gKcIPJEX4gaQI\nP5AUt+5Obs+ePaXtH3zwQWn7hRdeWNp+/Pjxlm0nTpwo/SzqRc8PJEX4gaQIP5AU4QeSIvxAUoQf\nSIrwA0m1vXV3pSvj1t1zzrPPPlvaPj4+Xtr+0EMPlbajelXeuhvAGYjwA0kRfiApwg8kRfiBpAg/\nkBThB5LiPD9whuE8P4BShB9IivADSRF+ICnCDyRF+IGkCD+QVNvw277c9jO2X7P9qu27iun32z5k\n+6XiMVx/uQCq0vYiH9uDkgYj4kXbF0jaI+lGSTdL+igifj3rlXGRD1C72V7k03bEnoiYkDRRvD5m\n+3VJi7orD0DTTuuY3/YVkpZKer6YdKftl21vtH1Ri8+M2N5te3dXlQKo1Kyv7bd9vqTnJP0yIrbZ\nHpD0nqSQ9AtNHRqsabMMdvuBms12t39W4bd9jqQnJT0VEV+4I2OxR/BkRFzTZjmEH6hZZT/ssW1J\nGyS9Pj34xReBJ90kae/pFgmgObP5tn+ZpL9IekXSyTGV75W0StISTe32H5B0e/HlYNmy6PmBmlW6\n218Vwg/Uj9/zAyhF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQf\nSKrtDTwr9p6kt6e9v7iY1o/6tbZ+rUuitk5VWdtXZztjT3/P/4WV27sjYqixAkr0a239WpdEbZ1q\nqjZ2+4GkCD+QVNPhH214/WX6tbZ+rUuitk41Ulujx/wAmtN0zw+gIY2E3/YK22/Y3m97bRM1tGL7\ngO1XipGHGx1irBgGbdL23mnTFtjebntf8TzjMGkN1dYXIzeXjCzd6LbrtxGve77bb/ssSW9Kul7S\nQUkvSFoVEa/1tJAWbB+QNBQRjZ8Ttv0dSR9J2nxyNCTbv5J0NCIeLP5xXhQRP+2T2u7XaY7cXFNt\nrUaW/pEa3HZVjnhdhSZ6/msl7Y+ItyLiU0mPSVrZQB19LyJ2Sjp6yuSVksaK12Oa+uPpuRa19YWI\nmIiIF4vXxySdHFm60W1XUlcjmgj/IknvTHt/UP015HdIetr2HtsjTRczg4FpIyMdljTQZDEzaDty\ncy+dMrJ032y7Tka8rhpf+H3Rsoj4pqTvS7qj2L3tSzF1zNZPp2sekXSVpoZxm5C0rsliipGlt0q6\nOyI+nN7W5Laboa5GtlsT4T8k6fJp7y8rpvWFiDhUPE9KelxThyn95MjJQVKL58mG6/mfiDgSEccj\n4oSk9Wpw2xUjS2+V9GhEbCsmN77tZqqrqe3WRPhfkHS17Sttf1nSLZLGG6jjC2yfV3wRI9vnSbpB\n/Tf68Lik1cXr1ZKeaLCWz+mXkZtbjSythrdd3414HRE9f0ga1tQ3/v+U9LMmamhR19ck/b14vNp0\nbZK2aGo38D+a+m7kNklfkbRD0j5Jf5a0oI9q+62mRnN+WVNBG2yotmWa2qV/WdJLxWO46W1XUlcj\n240r/ICk+MIPSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBS/wVBB9VJtxtLyAAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDcaMr5ACafz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))\n",
        "\n",
        "def softmax(x):\n",
        "  return torch.exp(x)/torch.sum(torch.exp(x))\n",
        "\n",
        "input = images.view(images.shape[0], 784)\n",
        "\n",
        "w1 = torch.randn(784, 256)\n",
        "b1 = torch.randn(256)\n",
        "\n",
        "w2 = torch.randn(256, 10)\n",
        "b2 = torch.randn(10)\n",
        "\n",
        "h1 = activation(torch.mm(input, w1)+ b1)\n",
        "output = activation(torch.mm(h1, w2) + b2)\n",
        "final = softmax(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "944anU5cGwn-",
        "colab_type": "code",
        "outputId": "b21dc0ab-68c5-4826-abea-652fe9635d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(output)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[9.6746e-01, 3.5283e-03, 6.5076e-01, 4.0305e-03, 1.0000e+00, 9.9984e-01,\n",
            "         6.9548e-02, 1.3046e-03, 6.5271e-03, 9.9299e-01],\n",
            "        [4.8937e-02, 9.1439e-01, 9.6750e-01, 8.4181e-01, 1.0000e+00, 9.9978e-01,\n",
            "         2.1468e-03, 2.4613e-02, 8.7345e-04, 9.9975e-01],\n",
            "        [8.4335e-01, 9.6826e-01, 9.9974e-01, 6.4972e-03, 1.0000e+00, 9.9904e-01,\n",
            "         1.8147e-04, 9.1311e-06, 5.8273e-03, 9.9997e-01],\n",
            "        [2.2849e-01, 9.7540e-01, 1.0000e+00, 6.5074e-01, 1.0000e+00, 9.8749e-01,\n",
            "         2.2684e-04, 8.1573e-06, 7.7573e-03, 9.9652e-01],\n",
            "        [3.2479e-01, 1.0990e-01, 9.6206e-01, 4.9619e-03, 1.0000e+00, 9.9795e-01,\n",
            "         1.6699e-06, 9.1671e-03, 2.2388e-03, 9.9999e-01],\n",
            "        [9.9581e-01, 8.7552e-01, 9.9979e-01, 2.2023e-03, 1.0000e+00, 9.9903e-01,\n",
            "         9.3793e-01, 9.9769e-01, 2.6277e-02, 9.8965e-01],\n",
            "        [2.3466e-03, 1.6845e-01, 9.9911e-01, 5.4571e-03, 1.0000e+00, 1.0000e+00,\n",
            "         9.9818e-01, 9.7218e-02, 4.2019e-02, 9.9869e-01],\n",
            "        [2.3809e-03, 9.9999e-01, 9.9914e-01, 9.7178e-01, 1.0000e+00, 9.9863e-01,\n",
            "         1.2388e-02, 7.7994e-05, 6.6093e-01, 4.8447e-01],\n",
            "        [5.2652e-01, 1.9319e-01, 1.0000e+00, 1.1411e-03, 1.0000e+00, 1.0000e+00,\n",
            "         3.1371e-03, 6.2411e-02, 4.6057e-05, 8.4557e-01],\n",
            "        [9.9405e-01, 1.8883e-04, 9.8711e-01, 2.4763e-03, 1.0000e+00, 1.0000e+00,\n",
            "         1.6082e-04, 6.0396e-05, 6.5930e-04, 8.5005e-01],\n",
            "        [9.7935e-01, 8.2363e-01, 9.9901e-01, 1.4730e-04, 1.0000e+00, 9.9438e-01,\n",
            "         3.4188e-01, 7.4805e-01, 9.8579e-01, 9.9998e-01],\n",
            "        [3.4570e-03, 2.6355e-02, 1.0000e+00, 2.0509e-01, 1.0000e+00, 9.9999e-01,\n",
            "         5.5769e-02, 7.9706e-01, 2.9978e-01, 1.4398e-01],\n",
            "        [1.8664e-01, 8.4816e-01, 9.8506e-01, 8.6313e-01, 1.0000e+00, 1.0000e+00,\n",
            "         6.9079e-02, 2.6437e-05, 4.1165e-04, 1.2032e-02],\n",
            "        [1.8743e-01, 9.9571e-01, 9.9774e-01, 1.4774e-03, 1.0000e+00, 1.0000e+00,\n",
            "         3.8699e-02, 4.7298e-03, 4.6014e-04, 9.9994e-01],\n",
            "        [9.9385e-01, 4.4758e-03, 9.9999e-01, 6.4888e-02, 1.0000e+00, 9.9906e-01,\n",
            "         5.0271e-01, 3.8175e-02, 7.9163e-03, 9.9999e-01],\n",
            "        [2.5934e-01, 3.3338e-01, 9.9997e-01, 3.4137e-02, 1.0000e+00, 9.9995e-01,\n",
            "         1.6440e-02, 1.8349e-02, 5.3209e-01, 9.9991e-01],\n",
            "        [4.7737e-01, 9.9586e-01, 8.0224e-01, 6.2600e-01, 1.0000e+00, 9.6250e-01,\n",
            "         9.1740e-03, 8.4252e-05, 7.8511e-04, 9.8898e-01],\n",
            "        [9.2621e-01, 9.9845e-01, 8.2803e-01, 7.9598e-04, 1.0000e+00, 1.0000e+00,\n",
            "         9.4611e-01, 5.2021e-02, 5.9790e-06, 9.3659e-01],\n",
            "        [5.8790e-02, 9.9909e-01, 9.9857e-01, 3.8844e-05, 1.0000e+00, 1.0000e+00,\n",
            "         9.9384e-01, 4.1163e-05, 1.6154e-01, 9.9391e-01],\n",
            "        [9.9057e-01, 8.8641e-01, 9.7139e-01, 5.3998e-02, 1.0000e+00, 9.9997e-01,\n",
            "         1.2930e-02, 2.4670e-04, 7.3538e-01, 9.9999e-01],\n",
            "        [9.9260e-01, 9.9989e-01, 9.9986e-01, 1.3113e-03, 1.0000e+00, 9.9993e-01,\n",
            "         1.2726e-03, 7.1968e-01, 2.9825e-06, 9.9988e-01],\n",
            "        [9.7344e-01, 3.3590e-01, 9.1672e-01, 8.9827e-01, 1.0000e+00, 1.0000e+00,\n",
            "         1.8539e-03, 3.4587e-05, 2.8251e-03, 9.9350e-01],\n",
            "        [1.5842e-01, 4.9245e-01, 9.9822e-01, 9.8326e-01, 1.0000e+00, 9.7558e-01,\n",
            "         1.0107e-01, 2.9869e-01, 4.2147e-05, 8.0353e-01],\n",
            "        [4.9238e-01, 1.1201e-01, 9.9878e-01, 6.3195e-05, 1.0000e+00, 8.1887e-01,\n",
            "         4.2270e-04, 4.3917e-03, 6.3560e-03, 9.9897e-01],\n",
            "        [1.0322e-04, 9.9993e-01, 1.0000e+00, 2.5419e-05, 1.0000e+00, 1.0000e+00,\n",
            "         9.7510e-01, 2.3034e-04, 9.6277e-01, 9.9999e-01],\n",
            "        [9.4770e-01, 9.8687e-01, 9.9959e-01, 9.6031e-01, 1.0000e+00, 1.0000e+00,\n",
            "         9.0120e-01, 3.8487e-05, 4.2162e-03, 4.4315e-01],\n",
            "        [9.3308e-01, 7.9791e-01, 3.6580e-01, 4.7217e-03, 1.0000e+00, 9.9998e-01,\n",
            "         6.4735e-03, 8.6010e-08, 2.2988e-02, 9.9859e-01],\n",
            "        [2.7561e-05, 7.3308e-01, 1.0000e+00, 2.5174e-04, 1.0000e+00, 9.9999e-01,\n",
            "         2.8261e-01, 9.7360e-01, 3.7682e-05, 9.6279e-01],\n",
            "        [2.1214e-02, 9.9987e-01, 9.9772e-01, 1.0930e-06, 1.0000e+00, 1.0000e+00,\n",
            "         2.6470e-01, 5.5689e-03, 1.1645e-06, 1.0000e+00],\n",
            "        [9.9555e-04, 9.9996e-01, 9.9973e-01, 9.7691e-01, 1.0000e+00, 1.0000e+00,\n",
            "         9.1811e-03, 1.2681e-01, 4.7178e-08, 9.9999e-01],\n",
            "        [9.9735e-01, 1.9929e-01, 8.9503e-01, 1.1583e-03, 1.0000e+00, 9.9995e-01,\n",
            "         9.9997e-01, 3.6921e-05, 5.5455e-02, 1.3621e-01],\n",
            "        [2.5841e-02, 1.3781e-01, 1.0000e+00, 2.0443e-03, 1.0000e+00, 1.0000e+00,\n",
            "         8.6647e-01, 6.7605e-02, 4.1361e-02, 9.9821e-01],\n",
            "        [7.3358e-01, 8.3995e-02, 1.0335e-01, 1.0142e-01, 1.0000e+00, 1.1700e-01,\n",
            "         7.1695e-03, 6.4727e-02, 8.1723e-01, 7.2356e-01],\n",
            "        [2.2966e-01, 5.3820e-01, 2.5031e-02, 4.3843e-03, 1.0000e+00, 4.2409e-01,\n",
            "         7.6961e-07, 2.2815e-02, 4.7353e-04, 9.6373e-01],\n",
            "        [7.5817e-02, 9.9539e-01, 1.0000e+00, 1.2170e-02, 1.0000e+00, 1.0000e+00,\n",
            "         4.2003e-01, 9.7328e-01, 7.1755e-04, 9.9979e-01],\n",
            "        [7.0864e-01, 1.0000e+00, 2.5514e-01, 8.3011e-09, 1.0000e+00, 9.9226e-01,\n",
            "         9.2482e-01, 4.7416e-04, 1.4989e-06, 9.9958e-01],\n",
            "        [2.1508e-01, 2.3581e-05, 8.4662e-01, 3.0930e-06, 1.0000e+00, 9.9998e-01,\n",
            "         1.0616e-03, 9.9489e-01, 4.4993e-03, 4.5536e-01],\n",
            "        [8.2970e-01, 9.4468e-01, 9.2355e-01, 2.9125e-03, 1.0000e+00, 1.0000e+00,\n",
            "         6.6275e-04, 1.5192e-05, 3.4682e-01, 9.9317e-01],\n",
            "        [2.5509e-02, 7.2608e-02, 1.0000e+00, 8.8027e-01, 1.0000e+00, 9.9999e-01,\n",
            "         7.0128e-01, 1.4240e-04, 7.2183e-02, 9.8822e-01],\n",
            "        [9.2745e-01, 9.9998e-01, 9.9221e-01, 7.4810e-06, 1.0000e+00, 9.9999e-01,\n",
            "         9.9996e-01, 4.9202e-03, 9.7157e-01, 9.9998e-01],\n",
            "        [5.0225e-01, 2.0609e-01, 9.9809e-01, 5.7051e-02, 1.0000e+00, 9.9058e-01,\n",
            "         1.9992e-03, 9.6352e-01, 4.6677e-01, 9.8611e-01],\n",
            "        [1.8310e-02, 4.6777e-01, 9.7972e-01, 1.3315e-01, 1.0000e+00, 6.4350e-01,\n",
            "         6.0851e-09, 4.6103e-06, 1.2441e-03, 3.9272e-03],\n",
            "        [9.5893e-01, 9.7623e-01, 9.9853e-01, 9.9945e-01, 1.0000e+00, 9.9096e-01,\n",
            "         1.5289e-01, 1.2129e-02, 9.6795e-01, 9.6101e-01],\n",
            "        [1.4684e-02, 9.5750e-08, 9.9997e-01, 4.9012e-03, 1.0000e+00, 9.9998e-01,\n",
            "         9.9868e-01, 4.1451e-01, 2.6270e-05, 9.9306e-01],\n",
            "        [8.8142e-01, 1.3918e-02, 9.9958e-01, 1.7604e-03, 1.0000e+00, 9.9990e-01,\n",
            "         7.6834e-01, 9.1685e-07, 3.2655e-05, 7.2849e-01],\n",
            "        [3.2010e-01, 9.9983e-01, 1.0000e+00, 7.4364e-03, 1.0000e+00, 9.9518e-01,\n",
            "         3.1109e-02, 8.4154e-02, 3.0282e-01, 8.1157e-01],\n",
            "        [6.8421e-01, 4.8043e-01, 4.5307e-03, 1.3299e-04, 1.0000e+00, 1.0000e+00,\n",
            "         2.3130e-02, 2.3068e-05, 5.7716e-02, 9.6144e-01],\n",
            "        [9.9936e-01, 9.9995e-01, 3.6650e-01, 6.3557e-01, 1.0000e+00, 9.9995e-01,\n",
            "         7.9375e-02, 1.6523e-01, 9.5764e-01, 9.9754e-01],\n",
            "        [9.9986e-01, 1.0000e+00, 2.7471e-02, 9.5415e-01, 1.0000e+00, 9.9998e-01,\n",
            "         7.8235e-05, 1.2078e-02, 9.5313e-01, 1.3343e-01],\n",
            "        [9.9937e-01, 1.3736e-02, 6.7925e-01, 1.8312e-02, 1.0000e+00, 9.9817e-01,\n",
            "         1.7946e-01, 1.0604e-02, 2.7738e-01, 2.2226e-01],\n",
            "        [7.2011e-01, 3.7159e-01, 8.7609e-01, 3.7981e-03, 1.0000e+00, 9.8007e-01,\n",
            "         1.9020e-01, 3.7444e-01, 2.6820e-02, 9.9883e-01],\n",
            "        [6.2235e-03, 6.7440e-01, 9.9997e-01, 8.7663e-01, 1.0000e+00, 1.0000e+00,\n",
            "         2.9849e-02, 3.3810e-02, 1.3868e-02, 9.9413e-01],\n",
            "        [9.9830e-01, 9.9268e-01, 1.1328e-02, 9.9916e-01, 1.0000e+00, 9.9974e-01,\n",
            "         1.7149e-04, 1.9281e-01, 8.1646e-01, 5.4863e-01],\n",
            "        [5.4051e-01, 2.8383e-02, 9.8269e-01, 4.2398e-04, 1.0000e+00, 9.9991e-01,\n",
            "         9.6213e-01, 4.5986e-03, 6.1631e-03, 9.7247e-01],\n",
            "        [3.2920e-05, 7.8123e-01, 9.9864e-01, 6.3733e-01, 1.0000e+00, 9.9997e-01,\n",
            "         1.8374e-01, 2.1175e-04, 8.0104e-04, 9.9999e-01],\n",
            "        [9.9798e-01, 9.9963e-01, 3.0462e-01, 1.2650e-04, 1.0000e+00, 9.9985e-01,\n",
            "         2.9395e-01, 1.4149e-03, 2.6328e-01, 9.9999e-01],\n",
            "        [9.0341e-01, 5.3659e-01, 9.9971e-01, 1.1466e-03, 1.0000e+00, 9.9989e-01,\n",
            "         3.7875e-01, 7.0852e-01, 2.7957e-02, 9.9456e-01],\n",
            "        [7.5240e-01, 1.0000e+00, 9.9995e-01, 3.2503e-07, 1.0000e+00, 1.0000e+00,\n",
            "         9.9958e-01, 1.2413e-02, 6.9418e-01, 1.0000e+00],\n",
            "        [9.7362e-01, 9.7275e-01, 9.9935e-01, 3.3332e-02, 1.0000e+00, 9.9985e-01,\n",
            "         2.7074e-01, 2.1983e-03, 1.3908e-05, 8.9771e-01],\n",
            "        [5.6754e-01, 1.0000e+00, 6.6528e-01, 7.2515e-03, 1.0000e+00, 9.9869e-01,\n",
            "         2.3797e-02, 8.0003e-08, 8.5974e-01, 9.6675e-01],\n",
            "        [9.9775e-01, 7.1276e-01, 9.9660e-01, 9.9314e-03, 1.0000e+00, 1.0000e+00,\n",
            "         2.4227e-08, 7.9557e-01, 7.5521e-05, 1.0000e+00],\n",
            "        [4.9788e-01, 9.8825e-01, 9.6144e-01, 1.9172e-01, 1.0000e+00, 9.9988e-01,\n",
            "         8.2928e-07, 8.7571e-01, 4.3202e-01, 8.7551e-01],\n",
            "        [5.4605e-01, 9.9981e-01, 9.9417e-01, 8.5722e-01, 1.0000e+00, 9.9994e-01,\n",
            "         9.2594e-01, 6.6777e-01, 3.4841e-01, 3.8550e-01],\n",
            "        [2.5392e-03, 5.3147e-01, 9.9932e-01, 2.5468e-05, 1.0000e+00, 1.0000e+00,\n",
            "         9.2092e-01, 9.9402e-01, 1.8453e-05, 9.8283e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvbsirOnZYYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldV6wLa3Z8I7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden1 = nn.Linear(784, 256)\n",
        "    self.hidden2 = nn.Linear(256, 128)\n",
        "    self.hidden3 = nn.Linear(128, 64)\n",
        "    self.output = nn.Linear(64, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.hidden1(x))\n",
        "    x = F.relu(self.hidden2(x))\n",
        "    x = F.relu(self.hidden3(x))\n",
        "    x = F.softmax(self.output(x), dim=1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyqYiBXBdtXU",
        "colab_type": "code",
        "outputId": "3ded49a6-42bb-4149-d8b3-e42cbf115fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "model1 = Classifier()\n",
        "model1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier(\n",
              "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
              "  (hidden2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (hidden3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1A6bnGYg8EH",
        "colab_type": "code",
        "outputId": "959c5a68-9e95-4a85-cfb1-2b716d5086d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10), nn.LogSoftmax(dim=1))\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = iter(trainloader).next()\n",
        "images = images.view(images.shape[0], -1)\n",
        "prediction = model(images)\n",
        "loss = criterion(prediction, labels)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "print(model)\n",
        "print(model.state_dict().keys())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax()\n",
            ")\n",
            "odict_keys(['0.weight', '0.bias', '2.weight', '2.bias', '4.weight', '4.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEzlUT1chQj1",
        "colab_type": "code",
        "outputId": "35a7246f-5335-4b1b-f3f0-83093d8a853f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    optimizer.zero_grad()\n",
        "    prediction = model.forward(images)\n",
        "    loss = criterion(prediction, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "  print(f\"training loss: {running_loss/len(trainloader)}\")\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "      images = images.view(images.shape[0], -1)\n",
        "      outputs = model(images)\n",
        "      _, pred = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (pred == labels).sum().item()\n",
        "    print(correct/total)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training loss: 0.23779570808542816\n",
            "0.9318\n",
            "training loss: 0.23283250642213613\n",
            "0.9348\n",
            "training loss: 0.22778911406456281\n",
            "0.9334\n",
            "training loss: 0.2229902592580964\n",
            "0.9354\n",
            "training loss: 0.21839798519860454\n",
            "0.939\n",
            "training loss: 0.21343930158565547\n",
            "0.9393\n",
            "training loss: 0.2091581449309773\n",
            "0.9399\n",
            "training loss: 0.20432010540432893\n",
            "0.9374\n",
            "training loss: 0.1999247055858183\n",
            "0.9425\n",
            "training loss: 0.19561521175192365\n",
            "0.9425\n",
            "training loss: 0.1914589295008861\n",
            "0.9437\n",
            "training loss: 0.18713130083070126\n",
            "0.9448\n",
            "training loss: 0.18329561419530846\n",
            "0.9463\n",
            "training loss: 0.17941379937520033\n",
            "0.9454\n",
            "training loss: 0.17560796293892714\n",
            "0.9481\n",
            "training loss: 0.17199897533381925\n",
            "0.9481\n",
            "training loss: 0.16833393851211712\n",
            "0.9484\n",
            "training loss: 0.164773072884567\n",
            "0.9508\n",
            "training loss: 0.16167052265709397\n",
            "0.9496\n",
            "training loss: 0.1583564058541934\n",
            "0.9519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ec4sSvJQLKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}